% Chapter 6

\chapter{Related Work} % Main chapter title
\label{Related Work} % For referencing the chapter elsewhere, use \ref{Chapter1} 
The related work section presented in this thesis, focuses on the state of the art in Cloud Computing in regard to it's monitoring, scheduling and SLA management capabilities. Therefore this chapter was divided into five categories, namely: (1) Infrastructure Measurements and Cloud Monitoring, (2) SLA Modeling and Description Languages, (3) Performance Prediction, (4) Scheduling Mechanisms and (5) SLA Enforcement, as well as (6) Autonomic Computing.

\section{Infrastructure Measurements and Cloud Monitoring}
Cloud Computing today delivers nearly unlimited scalable on demand computing resources within a few clicks. But the monitoring and government of such resources may come with some requirements. Monitoring is one of the fundamental parts of every cloud platform, since monitoring is needed to scale applications or instances correctly based on their resource utilization. It is also need to detect and discover defects and limitations, such as bottlenecks in the infrastructure environment. Additionally monitoring can give viable insights to both Cloud users and providers by revealing usage patterns and trends. Without any form of monitoring Cloud providers would not even be able to invoice their customer correctly, since they would not be able to tell how much ressouces and for how log the customer has used them. Cloud Monitoring has many ties into different Cloud Management fields such as capacity and resource planning and management, SLA management, incident management and troubleshooting, performance management and billing. An early example towards distributed resources monitoring is NetLogger \cite{DBLP:conf/mascots/2000}, a distributed monitoring system, which could monitor and collect network information. Published in 2000, application could use NetLoggers API to gather load information of the network and react accordingly. With GridEye \cite{Fu:2006:GSG:1170138.1170724} a service-oriented monitoring system, with an flexible, scaleable architecture and forecasting algorithm for performance prediction on the basis of traditional MA(k) and ExS(alpha) models was purposed. In 2009 Sandpiper \cite{Wood:2009:SBG:1663647.1663710} was proposed, a system, which automatically could monitor and detect hotspots and based on that remap or reconfigure VMs if necessary. The described system marks a first step towards autonomous SLA management, since the internal remaping algorithm considered SLA violations and to avoid them. 
In recent years various academic and commercial Cloud monitoring solutions have been proposed. In 2014 Jonathan Stuart Ward and Adam Barker \cite{ward2014observing} published a taxonomy of Cloud Monitoring stating scalability, cloud awareness, fault tolerance, aromaticity, comprehensiveness, timeliness and multiply granularity as core requirements towards effective Cloud monitoring. Fatema et al. \cite{fatema2014survey} and Aceto et al. \cite{aceto2013cloud} analized the most common open source and commercial monitoring solutions, such as Nagios, Collectd, Ganglia, IBM Tivoli, Amazon Cloud Watch, Azure Watch, PCMONS, mOSAIC, CASViD and many more, according on how they relate with these requirements. Recently Manasha Saqib \cite{saqib2017cloud} apportioned these requirements along the seven layers of Cloud Computing accoring to \cite{CSA3.0} \cite{spring2011monitoring1} \cite{spring2011monitoring2}: Facility, Network, Hardware, Operating System (OS), Middleware, Application and User. These studies provided a comprehensive overview of the available monitoring tools and their ability to support Cloud operational management, but also stated their shortcomings in the different areas. Cloud Monitoring in this thesis is considered as an enablement technology. The proposed architecture and algorithms are able to work with different monitoring solutions. The main focus thereby lies within the acquisition and enhancement ot such methodologies with additional information.
An additional topic especially in the area of PaaS is the application monitoring and application performance monitoring in the cloud.The definition of application performance management by Menasce \cite{menasce2002load}: APM is a collection of management processes used by organizations to ensure that the QoS of their e-business applications meets the business goals. So APM directly aims at the application life cycle and management processes such as monitoring, resource management, performance-management, reporting and so on, of software systems. According to Gartner \cite{GartnerAPM} there are several established big names in APM such as IBM, Oracle, BMC and so on, that are getting challenges by innovative start-ups such as AppDynamics or Dynatrace, and Correlsense. APM can be used as performance analysis and monitoring agents in SaaS and PaaS, and as such will be an topic for future work.


\section{SLA Modeling and Description Languages}
SLA attributes and its criteria are investigated for cloud computing by Alhamad et al. \cite{5610586}. This study determined the individual SLA metrics for SaaS, PaaS and IaaS separately. Although specific metrics are presented based on their layer requirements, they never considered the SLAs relation and hierarchical nature of cloud computing. In 2003 IBM developed the Web Service Agreement Language (WSLA) \cite{Ludwig03WSLA} which is still available in the Version 1.0 that dates back to the same year. It has not been further developed since. WSLA focused on performance and availability metrics. It seriously lacks expression therefore it is not powerful enough. The required flexibility is also missing which is needed for dynamical changes at run time. It is closely connected to their XML schema and not very useful to determine conclusion. WSLA has been mainly developed for Web services, its usage in other fields is questionable. It shows significant shortcomings regarding content as it focusses mainly on technical properties. The structural requirements, however, are met as discussed in Spillner et.al. \cite{Spillner2009}. Patel et al. \cite{Patel2009ServiceLA} proposed the WSLA framework for SLA enforcement in cloud computing. This framework is not enough adapted for cloud needs, cloud computing nature. Some other frameworks include RESTful \cite{Kubert:2011:RIW:1967428.1967444}, SALmonADA \cite{6225938}, SLA@SOI \cite{slasoi2011}, which all have put aside the hierarchical nature of cloud computing. They have directly applied the SLA structure in the cloud computing area from SOA and grid computing. The SSV architecture proposed by Kertesz et al. \cite{5739040} which contracted the SLA between an individual service provider and consumer after the negotiation process. However, they did not consider the hierarchical relation of SLAs in the cloud environment. Although a research by Undheim et al. \cite{6076508} attempted to deploy the on demand SLAs with QoS details on different levels, it followed the common SLA structure with stated shortcomings. NIST \cite{Liu2011} has also pointed out the necessity of SLAs, SLA management, definition of contracts, orientation of monitoring on Service Level Objects (SLOs) and how to enforce them. However a clear definition of a reference of a specific format is missing. This is also the case with the Internet Engineering Task Force (IETF) \cite{Khasnabish2010}. Besides these approaches of the companies and organisations there are further efforts to develop and to realize cloud management architectures and systems. A basic discussion can be found in the book from Wieder et.al. \cite{Wieder2011} mainly concerned about SLA definitions and negotiations. CSLA \cite{kouki2014language} (Cloud Service Level Agreement) language was developed with main focus on dealing with QoS uncertainty and performance fluctuations in cloud services. CSLA specification can be defined in different programming languages and are not XML restricted. The Foundation of Self Governing ICT Infrastructures (FOSll)-Project \cite{fosii} is another research project which aims at the usage of autonomic principals for information and communication systems. Self determining infrastructures should be realized and made available through cloud based services. Within the LoM2HiS autonomic SLA management is realized by translation of system parameters to abstract KPIs and SLOs  \cite{Brandic:2009:VFE:1616056.1616063}. The SLA specification is based on WSAL. The Texo project \cite{texo2011} attempts within the THESEUS research program to realize a conception of service descriptions, contract management, end to end marketplaces and monitoring from a business perspective. In addition the development and use of WS-A based SLAs are needed. Looking at the cloud interfaces that describe the management of resources within the cloud, it becomes obvious that they are exclusively designed with the purpose of system monitoring. They do not provide a direct monitoring of SLAs. Therefore the placement of machine readable SLAs is extremely difficult. This is also the case with existing monitoring tools. SLA handling in clouds, resulting from the EU project OPTIMIS, is discussing negotiating and creating Service Level Agreements between infrastructure providers and service providers \cite{Lawrence:2010:USL:2050107.2050112}. Although it is enhanced within the SLA@SOI project \cite{slasoi2011} its development is unclear because the SLA@SOI project develop its own format SLA(T) \cite{slasoiwiki} and supported by the European IT industry. A comprehensive project result has been published on their web page. No independent analysis of the advantages or disadvantages of the SLA(T) format is available at the moment. It provides all structural requirements of a SLA and it has the greatest intersection with regard to content. SLA(T) is the basis of the proposed approach in this paper. Further it should be accentuated that a meta model SLA* \cite{slasoisrc} is defined which simplifies the extension and adaptability for SLA(T). SLA* is proposed as part of SLA@SOI European project to generalize the XML based web services standards WSLA, WS-Agreement and WSDL. The WS-Agreement (WS-A) was developed by the Open Grid Forum in the year 2007 (Version 1.0) The last update which was based on the work of the European SLA@SOI project was done in 2011. Its advantages are the expandability and the adaptability which is, on the other hand, also one of its greatest disadvantages because it has not been specified in details by Kearney \cite{Kearney2011b}. It is based on technical transformation, the structural transformations, however, have not been taken into account. SLAC \cite{uriarte2014slac} is based on WS-Agreement and inherits many features and structures from it. The SLA-Ready\cite{SLA-Ready} common reference model describes and promotes the uptake of cloud service level agreements, by providing a common understanding of SLAs for cloud services.



\section{Performance Prediction}
Neural Networks are widely used in forecasting problems. One of the earliest successful application of ANNs in forecasting is reported by Lapedes and Farber \cite{LapedesFarber87}. They used a feed-forward neural network with deterministic chaotic time series generated by the Glass-Mackey equation, to predict such dynamic non-linear systems.
Artificial Neural Networks are proven universal approximators \cite{Hornik1989359}\cite{Hornik1991251} and are able to forecast both linear \cite{Zhang20011183} and non-linear time series \cite{Zhang199835}. Adya and Collopy investigated in the effectiveness of Neural Networks (NN) for forecasting and prediction \cite{neural1}. They came to the conclusion that NN are well suited for the use of prediction, but need to be validated against a simple and well-accepted alternative method to show the direct value of this approach. Since forecasting problems are common to many different disciplines and diverse fields of research, it is very hard to be aware of all the work done in this area.  Some examples are forecasting applications such as: temperature and weather \cite{Langella2010328}\cite{Buizza}\cite{Roebber}, tourism \cite{Pattie1996151}, electricity load \cite{Park76685}\cite{Hippert910780}, financial and economics \cite{Bodyanskiy20061357}\cite{McAdam2005848}\cite{Kaastra1996215}\cite{Guresen201110389} and medical \cite{Vukicevic2014}\cite{Arizmendi20145296} to name a few. Zhang, Patuwo, and Hu \cite{Zhang199835} show multiple other fields where prediction by ANN was successfully implemented.

%While NNs powerful approximation capabilities and selfadaptive data driven modelling approach allow them great flexibility in modelling time series data, it also complicates substantially model specification and the estimation of their parameters. Direct optimisation through conventional minimisation of error is not possible under the multilayer architecture of NNs and the back- propagation learning algorithm has been proposed to solve this problem (Rumelhart, Hinton, & Williams, 1986), later discussed in the context of time series by Werbos (1990). Several complex training (optimisation) algorithms have appeared in the literature, which may nevertheless be stuck in local optima (Hagan, Demuth, & Beale, 1996; Haykin, 2009). To alleviate this problem, training of the networks may be initialised several times and the best network model selected according to some fitting criteria. However, this may still lead to suboptimal selection of parameters depending on the fitting criterion, resulting in loss of predictive power in the out-of-sample set (Hansen & Salamon, 1990). Another chal- lenge in the parameter estimation of NNs is due to the uncertainty associated with the training sample. Breiman (1996a) in his work on instability and stabilization in model selection showed that sub- set selection methods in regression, including artificial neural net- works, are unstable methods. Given a data set and a collection of models, a method is defined as unstable if a small change in the data results in large changes in the set of models.

Similar research with different focus has been conducted in the past for the use of machine learning in cloud environments. Prevost et al. used a Neural Network (NN), as well as a Linear Predictor \cite{prevost2011prediction} to anticipate future workloads by learning from historical URL requests. Although both models were able to give efficient predictions, the Linear Predictor was able to predict more accurately. Li and Wang proposed their modified Neural Network algorithm nn-dwrr in \cite{li2014sla}. The application of this algorithm led to a lowered average response time compared to application of traditional capacity based algorithms for scheduling incoming requests to VMs. In similar research Hu et al. \cite{hu2013kswsvr} have shown that their modification of a standard Support Vector Regression (SVR) algorithm can lead to an accurate forecasting of CPU Load what can be used to achieve a better resources utilization. Another algorithm, which is renowned for providing good results in similar scenarios, is Linear Regression. Although the results are often weaker compared to Neural Networks or Support Vector Machines (SVM) in cases of workload prediction \cite{bankole2013predicting} \cite{imam2011neural}, the fast training and deployment time of models built with Linear Regression should not be underestimated. Those examples show that there are a variety of optimization challenges in cloud environments which can be tackled by applying machine learning algorithms. What separates the current work from previous research is a detailed examination of specific characteristics of three different machine learning algorithms and presenting the results in a visual way. The choice to evaluate Neural Networks, Support Vector Machines and Linear Regression was made because those algorithms earned promising results in previously conducted research.


\section{Scheduling Mechanisms}
Most commonly found scheduling approaches for the Cloud, like proposed by Mao and Humphrey \cite{6114435} or Panda et al. \cite{PANDA2015176}, aim towards resource optimization based task scheduling. Therefore, cloud instances are regarded as computing tasks that have to be processed within certain resource constraints. However, this basic view is only suitable for cloud operations with already known tasks or performance requirements. In the real cloud environment, however, these are usually of no importance since cloud customers either do not know them or they are highly variable. The approach shown seems to have more applicability in grid computing. Many publications have been published in recent years regarding Grid Scheduling. This suggests a special interest in research in this area. In particular, the methods of nature-based algorithms, such as the evolutionary algorithms, are frequently used, cf. \cite{tlda} \cite{Ga-grid-2}. Heuristics, however, play an equally important role in practice, cf. \cite{riskheuristik}. The main approach in grid scheduling is to split tasks (workloads) in so-called jobs, which are distributed on the basis of their computational requirements (MIPS), so that the total processing time is minimal. The publication of \cite{4heurisitken} compares four popular approaches to grid scheduling. For this purpose, the ant algorithm, a genetic algorithm, a particle-swarm algorithm and simulated annealing were implemented on the basis of the same preconditions. Anyhow, the approaches of grid scheduling are not or only very difficult to transfer to the problem area of cloud scheduling or the scheduling of virtual machines, since these instances are based on time rather than tasks. The big difference is that jobs are displayed in a one-dimensional unit, mostly in MIPS. However, instances in cloud scheduling are defined by a two or more-dimensional combination of resources and time. For this, the solution methods must be strongly adapted and the expected results will deviate from the findings described above.

With the ever-increasing popularity of cloud computing, the number of research papers on the topic of cloud scheduling is increasing. For the problems of this thesis especially the work on the topics of virtual machine scheduling and cloud scheduling in the context of SLA awareness are interesting. Often grid scheduling approaches like \cite{ga-basedtask} and \cite{deadlineawarecloud}, are transferred to the cloud. Here a genetic algorithm is used but also simple algorithms like First-In-First-Out (FIFO) are used. The basis here, as in the case of grid scheduling, is the division into jobs that have a specific computing time requirement, which are then distributed to existing virtual machines within the cloud. Another approach of \cite{cloudbursting} shows how loads can be distributed to an external cloud, such as the Amazon Elastic Compute Cloud, by means of a so-called Bursting Scheduler. Here, too, jobs are represented as computing tasks. Seoyoung et al. \cite{adaptablecloudscheduling} deals with cloud scheduling for scientific applications. It should be noted that these applications have special requirements in terms of resources and computing time. Based on OpenNebula and Haizea\cite{haizea}, it could be proven that a shift of the scientific application into the cloud brings clear advantages. The same applies to \cite{twolevel} where the CloudSim Toolkit introduces a scheduling process for the processing of so-called process units (PE). The tasks are distributed to individual cloud instances to minimize the total processing time. The approach involves techniques such as backfilling, where smaller jobs may advance as long as they do not delay others' execution, and first-come-first-serve and round-robin algorithm, unfortunately, the approaches used are not transferable to the scheduling of cloud instances, but they show the power of the cloud computing approach itself. Haizea \cite{haizea2} itself is a resource manager or resource scheduler. Haizea  can manage a set of computers (typically a cluster), allowing users to request exclusive use of those resources described in a variety of terms, such as "I need 10 nodes, each with 1 GB of memory, right now" or "I need 4 nodes, each with 2 CPUs and 2GB of memory, from 2pm to 4pm tomorrow". Haizea provides reservation and deadline sensitive type of leases along with the traditional immediate and best effort policies \cite{haizea1} \cite{haizea3} \cite{haizea4}. Haizea uses simple allocation policies for deadline sensitive leases. It tries to find out a single slot of required time between startTime and endTime of the given lease which can allocate the requested resources. If it is unable to ?nd such a time slot, it rejects the lease. 


\section{SLA Enforcement}
SLA enforcement, especially in the are of cloud computing is an hot topic. Boniface et al. \cite{boniface2007dynamic} discuss dynamic service provisioning using GRIA SLAs. Here tge provisioning of services is based on pre agreed SLAs. The approach is based on Grid environments an they do not state how the low-level metrics are monitored and mapped to high-level SLAs. Comuzzi et al. \cite{5175897} define the process for SLA establishment adopted within the EU project SLA@SOI framework. Their architecture for monitoring SLAs considers only two requirements, the availability of historical data for evaluating SLA offers and the assessment of the capability to monitor the terms in an SLA offer. The SLAs-LoM2HiS framework \cite{emeakaroha2010low}uses a host monitor and run-time monitor. The first one is monitoring low-level resource metrics, whereas the latter is responsible for metric mapping and SLA violation monitoring. The framework tries to predict the SLA violations by predefining thresholds. Then alerts are notified into the internal knowledge component for possible adjustment in provider resource however there were not any other reaction strategies. It is part of the FOSII \cite{fosii} infrastructure, where they mainly tried to map the low level metrics into high level SLA by their monitoring method. \cite{articleEmeakaroha2013}.In this framework, the SLAs consist of attributes, metrics and formulas have to be located in a central repository. The QoSMONaaS approach \cite{articleQoSMONaas} focused to the QoS monitoring as a service. Although this flexible approach is a third party SLA monitoring system, it still needs the external service for SLA validating. Another related work is DeSVi architecture by Emeakaroha et al. \cite{EMEAKAROHA20121017}, which is designed based on LoM2HiS \cite{5547150} framework which limited for only one data centre as an IaaS. They applied the monitoring, analysis, planning and execution loop (MAPE) model to enforce the self-healing cloud computing. This architecture has beneficial for cloud management but not for sudden violation reaction. Overall the violation reaction process is rarely discussed in the mentioned SLA monitoring frameworks. The most of monitoring systems just tried to report the detected violations \cite{6225938} \cite{5175897} or assess the penalty cost of service providers \cite{10.1007/978-3-642-22709-7_46} \cite{Dastjerdi:2012:DOA:2275356.2275360}. However, an effective reaction process is needed to react against SLA violations. Some studies such as \cite{6212007}, \cite{6150077} and \cite{WANG20121135} utilized the SLAs to manage the provider resources without any reaction against violations. The SPECS project\cite{7430360} aims towards the secure provisioning of cloud services based on SLA management. Therefore security SLAs are negotiated between the provider and customer. However, if the security policies contained therein are not adhered to, the service is simply considered unsafe and then terminated.

\section{Autonomic Computing}
Autonomic computing refers to the ability of a distributed system to manage its resources with little or no human intervention. It was launched in 2001 by IBM to reduce the complexity of managing large distributed systems \cite{horn2001autonomic}. Autonomic computing aims to facilitate self-management of complex systems consisting of various components. Autonomic computing systems involve service-oriented technologies, agent technologies, adaptive control theory, machine learning, optimization theory, and many more \citep{fei2005design} \citep{zhao2009survey}. In cloud computing it helps to address the challenges of cloud management in an fast paced environment. Autonomic resource allocation \cite{inproceedingshu2009}, \cite{Casalicchio:2013:ARP:2494621.2494623} has been examined to meet the on demand thought of cloud computing. There are now many commercial approaches that can provide resources on the fly in a cloud system.
Other areas of research include autonomic self-testing \cite{5463688}, as well as autonomic life-cycle management \cite{brandic2009towards} in the cloud.

